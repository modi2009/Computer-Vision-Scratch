{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1240214,"sourceType":"datasetVersion","datasetId":711184}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Fault Detection with GC10-DET\n\nThis notebook is the **data preparation stage** of a portfolio project for defect detection on industrial surfaces.  \nDataset: [GC10-DET](https://www.kaggle.com/datasets/alex000kim/gc10det/data)\n\nSteps in this section:\n1. Explore the dataset  \n2. Visualize samples with bounding boxes  \n3. Build a custom PyTorch `Dataset`  \n4. Add data augmentation  \n5. Create DataLoaders for training/validation\n","metadata":{}},{"cell_type":"code","source":"# If running on Kaggle, most are preinstalled\n!pip install albumentations==1.4.0 --quiet\n\nimport os\nimport glob\nimport xml.etree.ElementTree as ET\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üóÇ Dataset Overview\n\n- **GC10-DET** contains 10 defect classes of metal surfaces.  \n- Images are stored under `images/` and annotations under `annotations/` (Pascal VOC XML).  \n- Task: object detection (bounding boxes + class).\n\nWe'll parse the annotations to understand:\n- How many images  \n- Class distribution  \n- Example annotation structure\n","metadata":{}},{"cell_type":"code","source":"source_folders = []\nfor folder in os.listdir('/kaggle/input/gc10det'):\n    try:\n        int(folder)\n        source_folders.append(os.path.join('/kaggle/input/gc10det', folder))\n    except:\n        pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"source_folders","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport glob\n\ndef combine_images_from_folders(source_folders, destination_folder):\n    \"\"\"\n    Combines all image files from a list of source folders into a single\n    destination folder.\n\n    Args:\n        source_folders (list): A list of strings, where each string is the\n                               path to a folder containing images.\n        destination_folder (str): The path to the folder where all images will\n                                  be copied. This folder will be created if it\n                                  does not exist.\n    \"\"\"\n    # Create the destination folder if it doesn't exist\n    os.makedirs(destination_folder, exist_ok=True)\n    \n    # Common image file extensions\n    image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n    \n    total_files_copied = 0\n\n    print(f\"Starting to combine images into '{destination_folder}'...\")\n\n    for folder in source_folders:\n        if not os.path.isdir(folder):\n            print(f\"Warning: Source folder '{folder}' not found. Skipping.\")\n            continue\n            \n        print(f\"Processing folder: '{folder}'\")\n        \n        # Use os.walk to find files in the current folder and its subdirectories\n        for root, _, files in os.walk(folder):\n            for filename in files:\n                # Check if the file has a valid image extension\n                if filename.lower().endswith(image_extensions):\n                    source_path = os.path.join(root, filename)\n                    dest_path = os.path.join(destination_folder, filename)\n                    \n                    # Handle potential duplicate filenames by adding a number\n                    if os.path.exists(dest_path):\n                        base, ext = os.path.splitext(filename)\n                        counter = 1\n                        while os.path.exists(os.path.join(destination_folder, f\"{base}_{counter}{ext}\")):\n                            counter += 1\n                        dest_path = os.path.join(destination_folder, f\"{base}_{counter}{ext}\")\n\n                    try:\n                        # shutil.copy2 preserves file metadata (timestamps, etc.)\n                        shutil.copy2(source_path, dest_path)\n                        total_files_copied += 1\n                    except IOError as e:\n                        print(f\"  Error copying file '{source_path}': {e}\")\n                    \n    print(\"\\n--- Combination Complete ---\")\n    print(f\"Total files copied: {total_files_copied}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_source = \"Images_all\"\ncombine_images_from_folders(source_folders, images_source)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mapping from the label-with-number to clean English name\nCLASS_MAP = {\n    \"1_chongkong\": \"punching_hole\",\n    \"2_hanfeng\": \"welding_line\",\n    \"3_yueyawan\": \"crescent_gap\",\n    \"4_shuibian\": \"water_spot\",\n    \"5_youbian\": \"oil_spot\",\n    \"6_siban\": \"silk_spot\",\n    \"7_yiwu\": \"inclusion\",\n    \"8_xiahen\": \"rolled_pit\",\n    \"9_zhehen\": \"crease\",\n    \"10_yaozhe\": \"waist_folding\"\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_DIR = \"/kaggle/working/Images_all\"\nANN_DIR = \"/kaggle/input/gc10det/lable\"\nprint()\nxml_files = glob.glob(os.path.join(ANN_DIR, \"*.xml\"))\nprint(f\"Total annotations: {len(xml_files)}\")\n\n# Parse one file to inspect structure\ntree = ET.parse(xml_files[0])\nroot = tree.getroot()\n\nfor obj in root.findall(\"object\"):\n    name = obj.find(\"name\").text\n    bbox = obj.find(\"bndbox\")\n    coords = [int(bbox.find(tag).text) for tag in [\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n    print(name, coords)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üñº Sample Images\n\nLet's plot a few raw images with their bounding boxes to verify labels.\n","metadata":{}},{"cell_type":"code","source":"def plot_image_with_boxes(img_path, ann_path):\n    img = np.array(Image.open(img_path).convert(\"RGB\"))\n    tree = ET.parse(ann_path)\n    boxes = []\n    labels = []\n    for obj in tree.findall(\"object\"):\n        labels.append(obj.find(\"name\").text)\n        bb = obj.find(\"bndbox\")\n        boxes.append([int(bb.find(t).text) for t in [\"xmin\",\"ymin\",\"xmax\",\"ymax\"]])\n    plt.imshow(img)\n    for box, lbl in zip(boxes, labels):\n        x1, y1, x2, y2 = box\n        plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n                                          fill=False, color='red', linewidth=2))\n        plt.text(x1, y1-5, lbl, color='red', fontsize=8, backgroundcolor='white')\n    plt.axis(\"off\")\n\nsample_files = random.sample(xml_files, 3)\nplt.figure(figsize=(15,5))\nfor i, ann in enumerate(sample_files):\n    plt.subplot(1,3,i+1)\n    img_file = os.path.join(IMG_DIR, os.path.basename(ann).replace(\".xml\",\".jpg\"))\n    plot_image_with_boxes(img_file, ann)\nplt.tight_layout()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üõ†Ô∏è Install & Import Ultralytics YOLO\n\nWe will use the **Ultralytics YOLO** implementation (v8/v11).  \nIt is lightweight, easy to train, and perfect for deployment.\n","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO\nimport os, glob, random, shutil\nfrom pathlib import Path\nimport xml.etree.ElementTree as ET\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1Ô∏è‚É£ Convert VOC XML annotations ‚Üí YOLO format\n\nWe create the standard YOLO folder structure:\n\n","metadata":{}},{"cell_type":"code","source":"import os, glob, shutil\nfrom tqdm import tqdm\n\n# paths\nROOT = \"/kaggle/working/gc10_yolo\"\nIMG_DIR = \"/kaggle/working/Images_all\"\nANN_DIR = \"/kaggle/input/gc10det/lable\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, glob, shutil, random\nfrom xml.etree import ElementTree as ET\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\nos.makedirs(f\"{ROOT}/images/train\", exist_ok=True)\nos.makedirs(f\"{ROOT}/images/val\", exist_ok=True)\nos.makedirs(f\"{ROOT}/labels/train\", exist_ok=True)\nos.makedirs(f\"{ROOT}/labels/val\", exist_ok=True)\n\nCLASSES = [\"scratch\"]   # only one class\n\ndef xml_to_yolo(xml_file, txt_file, img_w, img_h):\n    tree = ET.parse(xml_file)\n    lines = []\n    for obj in tree.findall(\"object\"):\n        bnd = obj.find(\"bndbox\")\n        xmin, ymin = float(bnd.find(\"xmin\").text), float(bnd.find(\"ymin\").text)\n        xmax, ymax = float(bnd.find(\"xmax\").text), float(bnd.find(\"ymax\").text)\n\n        x_c = ((xmin + xmax) / 2) / img_w\n        y_c = ((ymin + ymax) / 2) / img_h\n        w   = (xmax - xmin) / img_w\n        h   = (ymax - ymin) / img_h\n        lines.append(f\"0 {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\")  # always class 0\n\n    with open(txt_file, \"w\") as f:\n        f.write(\"\\n\".join(lines))\n\n\n# split train/val and copy\nall_xml = sorted(glob.glob(f\"{ANN_DIR}/*.xml\"))\nrandom.shuffle(all_xml)\nsplit = int(0.8 * len(all_xml))\ntrain_xml, val_xml = all_xml[:split], all_xml[split:]\n\nfor subset, xmls in [(\"train\", train_xml), (\"val\", val_xml)]:\n    for xml in tqdm(xmls, desc=f\"Preparing {subset}\"):\n        img_path = os.path.join(IMG_DIR, os.path.basename(xml).replace(\".xml\", \".jpg\"))\n        dst_img = f\"{ROOT}/images/{subset}/{os.path.basename(img_path)}\"\n        dst_txt = f\"{ROOT}/labels/{subset}/{os.path.basename(xml).replace('.xml', '.txt')}\"\n        w, h = Image.open(img_path).size\n        shutil.copy(img_path, dst_img)\n        xml_to_yolo(xml, dst_txt, w, h)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2Ô∏è‚É£ Define YOLO dataset configuration\n","metadata":{}},{"cell_type":"code","source":"import yaml\n\ndata_yaml = {\n    \"path\": ROOT,\n    \"train\": \"images/train\",\n    \"val\": \"images/val\",\n    \"nc\": len(CLASSES),\n    \"names\": CLASSES,\n}\n\nyaml_path = f\"{ROOT}/data.yaml\"\nwith open(yaml_path, \"w\") as f:\n    yaml.safe_dump(data_yaml, f, sort_keys=False)\n\nprint(open(yaml_path).read())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3Ô∏è‚É£ Train YOLOv8 on GC10\n","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolov9c.pt\")  # or yolov8n.pt for speed\nmodel.train(\n    data=yaml_path,\n    epochs=100,\n    imgsz=256,\n    batch=16,\n    project=\"gc10_yolo\",\n    name=\"exp\",\n    workers=4,\n    patience = 20\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4Ô∏è‚É£ Validate & Visualize YOLOv9-e results\n\nWe run evaluation on the validation split and plot some detections.\n","metadata":{}},{"cell_type":"code","source":"# Run evaluation on the validation set\nmetrics = model.val(data=yaml_path, imgsz=640, batch=16)\nprint(metrics)   # mAP, precision, recall, etc.\n\n# Predict on a few val images & save results\npred_results = model.predict(\n    source=f\"{ROOT}/images/val\",\n    conf=0.25,   # confidence threshold\n    save=True,   # saves annotated images into runs/predict/\n    imgsz=640\n)\n\n# Show one of the saved prediction images\nimport matplotlib.pyplot as plt\nimport glob\n\nsaved_imgs = glob.glob(\"runs/detect/predict*/**/*.jpg\", recursive=True)\nplt.figure(figsize=(10,10))\nplt.imshow(plt.imread(saved_imgs[0]))\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5Ô∏è‚É£ Save & Export YOLOv9-e weights\n\nWe store the trained model weights and also export to ONNX or TorchScript for deployment.\n","metadata":{}},{"cell_type":"code","source":"# Save the trained model (PyTorch format)\nbest_path = model.ckpt_path if hasattr(model, \"ckpt_path\") else model.trainer.best\nprint(f\"Best weights: {best_path}\")\n\n# Optionally export to other formats\nmodel.export(format=\"onnx\")        # ONNX\nmodel.export(format=\"torchscript\") # TorchScript\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.imshow(plt.imread(saved_imgs[0]))\nplt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}